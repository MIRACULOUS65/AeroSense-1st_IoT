{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14118081,"sourceType":"datasetVersion","datasetId":8993993}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Environmental LLM - Complete Training & RAG Chat\n## GPT-2 + Live OpenWeather API + SerpAPI Internet Search","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n!pip install -q transformers accelerate\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T03:18:49.815771Z","iopub.execute_input":"2025-12-12T03:18:49.815998Z","iopub.status.idle":"2025-12-12T03:19:53.670701Z","shell.execute_reply.started":"2025-12-12T03:18:49.815980Z","shell.execute_reply":"2025-12-12T03:19:53.669984Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, get_cosine_schedule_with_warmup\nimport json, random, os, requests\nfrom tqdm import tqdm\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Device: {device}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T03:19:53.671700Z","iopub.execute_input":"2025-12-12T03:19:53.671957Z","iopub.status.idle":"2025-12-12T03:20:04.456471Z","shell.execute_reply.started":"2025-12-12T03:19:53.671932Z","shell.execute_reply":"2025-12-12T03:20:04.455669Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765509599.443590     171 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765509599.450285     171 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# CONFIG\nDATA_PATH = '/kaggle/input/nothingg/real_api_training_data.jsonl'\nCKPT_DIR = '/kaggle/working/checkpoints'\nMAX_LEN, BATCH, GRAD_ACC = 256, 8, 4\nSTEPS, LR, WARMUP = 6000, 5e-5, 300\nos.makedirs(CKPT_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T03:20:04.457223Z","iopub.execute_input":"2025-12-12T03:20:04.457729Z","iopub.status.idle":"2025-12-12T03:20:04.462397Z","shell.execute_reply.started":"2025-12-12T03:20:04.457698Z","shell.execute_reply":"2025-12-12T03:20:04.461354Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# DATASET\nclass EnvDataset(Dataset):\n    def __init__(self, path, tokenizer, train=True):\n        self.tokenizer = tokenizer\n        samples = [json.loads(l) for l in open(path)]\n        idx = int(len(samples)*0.9)\n        self.samples = samples[:idx] if train else samples[idx:]\n        print(f\"{'Train' if train else 'Val'}: {len(self.samples):,}\")\n    def __len__(self): return len(self.samples)\n    def __getitem__(self, i):\n        s = self.samples[i]\n        text = f\"User: {s['input']}\\nAssistant: {s['output']}\"\n        enc = self.tokenizer(text, max_length=MAX_LEN, truncation=True, padding='max_length', return_tensors='pt')\n        return enc.input_ids.squeeze()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T03:20:04.463377Z","iopub.execute_input":"2025-12-12T03:20:04.463596Z","iopub.status.idle":"2025-12-12T03:20:04.491401Z","shell.execute_reply.started":"2025-12-12T03:20:04.463579Z","shell.execute_reply":"2025-12-12T03:20:04.490602Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# LOAD MODEL & DATA\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\nmodel = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\nprint(f'Model: {sum(p.numel() for p in model.parameters())/1e6:.0f}M params')\n\ntrain_ds = EnvDataset(DATA_PATH, tokenizer, train=True)\nval_ds = EnvDataset(DATA_PATH, tokenizer, train=False)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=BATCH)\nprint('Data loaded!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T03:20:04.492142Z","iopub.execute_input":"2025-12-12T03:20:04.492418Z","iopub.status.idle":"2025-12-12T03:20:05.840670Z","shell.execute_reply.started":"2025-12-12T03:20:04.492400Z","shell.execute_reply":"2025-12-12T03:20:05.840058Z"}},"outputs":[{"name":"stdout","text":"Model: 124M params\nTrain: 18,360\nVal: 2,040\nData loaded!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# TRAINING\noptimizer = AdamW(model.parameters(), lr=LR, weight_decay=0.01)\nscheduler = get_cosine_schedule_with_warmup(optimizer, WARMUP, STEPS)\nmodel.train()\nstep, best_val = 0, float('inf')\npbar = tqdm(total=STEPS)\n\nfor epoch in range(20):\n    for batch in train_loader:\n        ids = batch.to(device)\n        loss = model(ids, labels=ids).loss / GRAD_ACC\n        loss.backward()\n        if (step+1) % GRAD_ACC == 0:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n        step += 1\n        pbar.update(1)\n        pbar.set_postfix(loss=f'{loss.item()*GRAD_ACC:.4f}')\n        if step % 500 == 0:\n            model.eval()\n            val_loss = sum(model(b.to(device), labels=b.to(device)).loss.item() for b in val_loader)/len(val_loader)\n            print(f'\\nStep {step}: val_loss={val_loss:.4f}')\n            if val_loss < best_val:\n                best_val = val_loss\n                torch.save(model.state_dict(), f'{CKPT_DIR}/best_model.pt')\n                print('Saved best!')\n            model.train()\n        if step % 1500 == 0:\n            torch.save(model.state_dict(), f'{CKPT_DIR}/ckpt_{step}.pt')\n        if step >= STEPS: break\n    if step >= STEPS: break\npbar.close()\nprint(f'Done! Best val_loss: {best_val:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T03:20:05.842465Z","iopub.execute_input":"2025-12-12T03:20:05.842686Z","iopub.status.idle":"2025-12-12T04:30:26.015994Z","shell.execute_reply.started":"2025-12-12T03:20:05.842668Z","shell.execute_reply":"2025-12-12T04:30:26.015121Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/6000 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n  8%|â–Š         | 500/6000 [04:53<54:36,  1.68it/s, loss=0.3317]  ","output_type":"stream"},{"name":"stdout","text":"\nStep 500: val_loss=0.2303\n","output_type":"stream"},{"name":"stderr","text":"  8%|â–Š         | 501/6000 [05:46<25:04:49, 16.42s/it, loss=0.3317]","output_type":"stream"},{"name":"stdout","text":"Saved best!\n","output_type":"stream"},{"name":"stderr","text":" 17%|â–ˆâ–‹        | 1000/6000 [10:45<49:57,  1.67it/s, loss=0.1539]  ","output_type":"stream"},{"name":"stdout","text":"\nStep 1000: val_loss=0.1372\n","output_type":"stream"},{"name":"stderr","text":" 17%|â–ˆâ–‹        | 1001/6000 [11:38<22:47:39, 16.42s/it, loss=0.1539]","output_type":"stream"},{"name":"stdout","text":"Saved best!\n","output_type":"stream"},{"name":"stderr","text":" 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [16:37<44:39,  1.68it/s, loss=0.0811]   ","output_type":"stream"},{"name":"stdout","text":"\nStep 1500: val_loss=0.0887\nSaved best!\n","output_type":"stream"},{"name":"stderr","text":" 33%|â–ˆâ–ˆâ–ˆâ–      | 2000/6000 [22:29<39:43,  1.68it/s, loss=0.0639]   ","output_type":"stream"},{"name":"stdout","text":"\nStep 2000: val_loss=0.0563\n","output_type":"stream"},{"name":"stderr","text":" 33%|â–ˆâ–ˆâ–ˆâ–      | 2001/6000 [23:21<18:11:49, 16.38s/it, loss=0.0639]","output_type":"stream"},{"name":"stdout","text":"Saved best!\n","output_type":"stream"},{"name":"stderr","text":" 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [28:21<34:56,  1.67it/s, loss=0.0627]   ","output_type":"stream"},{"name":"stdout","text":"\nStep 2500: val_loss=0.0443\n","output_type":"stream"},{"name":"stderr","text":" 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [29:14<15:59:00, 16.44s/it, loss=0.0627]","output_type":"stream"},{"name":"stdout","text":"Saved best!\n","output_type":"stream"},{"name":"stderr","text":" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [34:13<29:57,  1.67it/s, loss=0.0450]   ","output_type":"stream"},{"name":"stdout","text":"\nStep 3000: val_loss=0.0402\nSaved best!\n","output_type":"stream"},{"name":"stderr","text":" 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [40:06<24:52,  1.67it/s, loss=0.0391]   ","output_type":"stream"},{"name":"stdout","text":"\nStep 3500: val_loss=0.0383\n","output_type":"stream"},{"name":"stderr","text":" 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [40:58<11:22:35, 16.39s/it, loss=0.0391]","output_type":"stream"},{"name":"stdout","text":"Saved best!\n","output_type":"stream"},{"name":"stderr","text":" 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [45:58<20:01,  1.67it/s, loss=0.0360]   ","output_type":"stream"},{"name":"stdout","text":"\nStep 4000: val_loss=0.0374\n","output_type":"stream"},{"name":"stderr","text":" 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [46:51<9:07:54, 16.45s/it, loss=0.0360]","output_type":"stream"},{"name":"stdout","text":"Saved best!\n","output_type":"stream"},{"name":"stderr","text":" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [51:50<14:54,  1.68it/s, loss=0.0356]  ","output_type":"stream"},{"name":"stdout","text":"\nStep 4500: val_loss=0.0366\nSaved best!\n","output_type":"stream"},{"name":"stderr","text":" 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5000/6000 [57:43<09:55,  1.68it/s, loss=0.0461]  ","output_type":"stream"},{"name":"stdout","text":"\nStep 5000: val_loss=0.0357\n","output_type":"stream"},{"name":"stderr","text":" 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5001/6000 [58:36<4:32:53, 16.39s/it, loss=0.0461]","output_type":"stream"},{"name":"stdout","text":"Saved best!\n","output_type":"stream"},{"name":"stderr","text":" 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5500/6000 [1:03:34<04:58,  1.67it/s, loss=0.0426]","output_type":"stream"},{"name":"stdout","text":"\nStep 5500: val_loss=0.0351\n","output_type":"stream"},{"name":"stderr","text":" 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5501/6000 [1:04:27<2:16:21, 16.40s/it, loss=0.0426]","output_type":"stream"},{"name":"stdout","text":"Saved best!\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6000/6000 [1:09:26<00:00,  1.66it/s, loss=0.0423]  ","output_type":"stream"},{"name":"stdout","text":"\nStep 6000: val_loss=0.0346\nSaved best!\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6000/6000 [1:10:20<00:00,  1.42it/s, loss=0.0423]","output_type":"stream"},{"name":"stdout","text":"Done! Best val_loss: 0.0346\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# === RAG SYSTEM: LIVE DATA + INTERNET SEARCH ===\nOPENWEATHER_API_KEY = '84fa0ee0ff4c054334d5ee962dd7c870'\nSERPAPI_KEY = '3435cc6097e3d0fe22e5846418cafd25ba4ab916526df5855cce55a9dbc6df64'\n\nCITIES = {\n    'kolkata': (22.57, 88.36), 'delhi': (28.61, 77.21), 'mumbai': (19.08, 72.88),\n    'bangalore': (12.97, 77.59), 'chennai': (13.08, 80.27), 'hyderabad': (17.38, 78.49),\n    'siliguri': (26.73, 88.40), 'darjeeling': (27.04, 88.27), 'durgapur': (23.52, 87.31),\n    'asansol': (23.67, 86.95), 'howrah': (22.59, 88.26), 'malda': (25.01, 88.14),\n}\n\ndef get_live_aqi(city):\n    '''Fetch LIVE AQI from OpenWeather'''\n    if city.lower() not in CITIES: return None\n    lat, lon = CITIES[city.lower()]\n    try:\n        url = f'http://api.openweathermap.org/data/2.5/air_pollution?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}'\n        r = requests.get(url, timeout=10)\n        if r.status_code == 200:\n            data = r.json()['list'][0]['components']\n            pm25 = data.get('pm2_5', 0)\n            # India AQI calculation\n            bp = [(0,30,0,50),(31,60,51,100),(61,90,101,200),(91,120,201,300),(121,250,301,400),(251,500,401,500)]\n            aqi = 500\n            for c_lo, c_hi, i_lo, i_hi in bp:\n                if c_lo <= pm25 <= c_hi:\n                    aqi = int(((i_hi-i_lo)/(c_hi-c_lo))*(pm25-c_lo)+i_lo)\n                    break\n            cat = 'Good' if aqi<=50 else 'Satisfactory' if aqi<=100 else 'Moderate' if aqi<=200 else 'Poor' if aqi<=300 else 'Very Poor' if aqi<=400 else 'Severe'\n            return {'aqi': aqi, 'category': cat, 'pm25': pm25, 'pm10': data.get('pm10', 0)}\n    except: pass\n    return None\n\ndef get_live_weather(city):\n    '''Fetch LIVE weather from OpenWeather'''\n    if city.lower() not in CITIES: return None\n    lat, lon = CITIES[city.lower()]\n    try:\n        url = f'http://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric'\n        r = requests.get(url, timeout=10)\n        if r.status_code == 200:\n            data = r.json()\n            return {'temp': data['main']['temp'], 'humidity': data['main']['humidity'], 'desc': data['weather'][0]['description']}\n    except: pass\n    return None\n\ndef search_internet(query):\n    '''Search the internet using SerpAPI'''\n    try:\n        url = f'https://serpapi.com/search.json?q={query}&api_key={SERPAPI_KEY}'\n        r = requests.get(url, timeout=15)\n        if r.status_code == 200:\n            data = r.json()\n            results = []\n            for item in data.get('organic_results', [])[:3]:\n                results.append({'title': item.get('title',''), 'snippet': item.get('snippet','')})\n            return results\n    except: pass\n    return None\n\nprint('RAG System Ready!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T04:30:26.017279Z","iopub.execute_input":"2025-12-12T04:30:26.017570Z","iopub.status.idle":"2025-12-12T04:30:26.029759Z","shell.execute_reply.started":"2025-12-12T04:30:26.017544Z","shell.execute_reply":"2025-12-12T04:30:26.029020Z"}},"outputs":[{"name":"stdout","text":"RAG System Ready!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# === RAG-ENHANCED GENERATION ===\n@torch.no_grad()\ndef rag_generate(prompt, max_tokens=150, temp=0.8):\n    model.eval()\n    context = ''\n    \n    # 1. Extract city and get LIVE data\n    for city in CITIES:\n        if city in prompt.lower():\n            aqi = get_live_aqi(city)\n            weather = get_live_weather(city)\n            if aqi:\n                context += f'[LIVE DATA: {city.title()} AQI={aqi[\"aqi\"]} ({aqi[\"category\"]}), PM2.5={aqi[\"pm25\"]:.1f}]\\n'\n            if weather:\n                context += f'[WEATHER: {weather[\"temp\"]}Â°C, {weather[\"humidity\"]}% humidity, {weather[\"desc\"]}]\\n'\n            break\n    \n    # 2. Search internet if needed\n    search_keywords = ['news', 'latest', 'research', 'study', 'why', 'how', 'cause', 'effect', 'climate']\n    if any(kw in prompt.lower() for kw in search_keywords):\n        results = search_internet(prompt + ' India environment')\n        if results:\n            context += f'[WEB SEARCH: {results[0][\"snippet\"][:150]}]\\n'\n    \n    # 3. Generate with context\n    full_prompt = f'{context}User: {prompt}\\nAssistant:' if context else f'User: {prompt}\\nAssistant:'\n    ids = tokenizer.encode(full_prompt, return_tensors='pt').to(device)\n    if ids.size(1) > 400: ids = ids[:, -400:]\n    \n    for _ in range(max_tokens):\n        out = model(ids)\n        logits = out.logits[:, -1, :] / temp\n        probs = F.softmax(logits, dim=-1)\n        next_id = torch.multinomial(probs, 1)\n        ids = torch.cat([ids, next_id], dim=1)\n        if next_id.item() == tokenizer.eos_token_id: break\n    \n    return tokenizer.decode(ids[0], skip_special_tokens=True).split('Assistant:')[-1].strip()\n\n# Load best model\nmodel.load_state_dict(torch.load(f'{CKPT_DIR}/best_model.pt'))\nprint('Model loaded!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T04:30:26.030649Z","iopub.execute_input":"2025-12-12T04:30:26.030934Z","iopub.status.idle":"2025-12-12T04:30:26.448995Z","shell.execute_reply.started":"2025-12-12T04:30:26.030910Z","shell.execute_reply":"2025-12-12T04:30:26.448322Z"}},"outputs":[{"name":"stdout","text":"Model loaded!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# === TEST RAG SYSTEM ===\nprint('\\n' + '='*60)\nprint('Testing RAG System with Live Data + Internet Search')\nprint('='*60 + '\\n')\n\ntest_queries = [\n    'What is the current AQI in Kolkata?',\n    'Compare air quality in Delhi vs Darjeeling',\n    'Why is pollution increasing in India?',\n    'Latest news about air quality'\n]\n\nfor q in test_queries:\n    print(f'Q: {q}')\n    response = rag_generate(q)\n    \n    # Add live data display\n    for city in CITIES:\n        if city in q.lower():\n            aqi = get_live_aqi(city)\n            if aqi:\n                response += f'\\n\\nğŸ“Š LIVE DATA ({city.title()}):'\n                response += f'\\nğŸ”´ AQI: {aqi[\"aqi\"]} ({aqi[\"category\"]})'\n                response += f'\\nğŸ’¨ PM2.5: {aqi[\"pm25\"]:.1f} Î¼g/mÂ³'\n            break\n    \n    print(f'A: {response}')\n    print('-'*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T04:30:26.449757Z","iopub.execute_input":"2025-12-12T04:30:26.449992Z","iopub.status.idle":"2025-12-12T04:30:39.137458Z","shell.execute_reply.started":"2025-12-12T04:30:26.449966Z","shell.execute_reply":"2025-12-12T04:30:39.136660Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTesting RAG System with Live Data + Internet Search\n============================================================\n\nQ: What is the current AQI in Kolkata?\nA: **Kolkata, West Bengal - Current Air Quality**\n\nğŸ“Š **AQI:** 457 (Severe)\nğŸ”´ **PM2.5:** 398.1 Î¼g/mÂ³\nğŸŸ  **PM10:** 446.9 Î¼g/mÂ³\n\nğŸŒ¡ï¸ **Weather:**\n- Temperature: 15.2Â°C\n- Humidity: 59%\n- Wind: 2.1 m/s\n\nâš ï¸ **Health Impact:** Serious health effects. Avoid outdoor activities.\n\nğŸ’¡ **Advisory:** Stay indoors. Keep windows closed. Use air purifiers. Seek medical attention if breathing issues occur.\n\nğŸ“Š LIVE DATA (Kolkata):\nğŸ”´ AQI: 424 (Severe)\nğŸ’¨ PM2.5: 309.9 Î¼g/mÂ³\n------------------------------------------------------------\nQ: Compare air quality in Delhi vs Darjeeling\nA: **Air Quality Comparison**\n\n| City | AQI | PM2.5 | Category |\n|------|-----|-------|----------|\n| Delhi | 252 | 106 | Poor |\n| Darjeeling | 460 | 398 | Severe |\n\nğŸ† **Winner:** Delhi has better air quality\nğŸ“Š **Difference:** 150 AQI points\n\nDelhi is significantly cleaner than the other city.\n\nğŸ“Š LIVE DATA (Delhi):\nğŸ”´ AQI: 299 (Poor)\nğŸ’¨ PM2.5: 120.0 Î¼g/mÂ³\n------------------------------------------------------------\nQ: Why is pollution increasing in India?\nA: **India Air Quality Report - Jalpaiguri**\n\nğŸ“ **Location:** Jalpaiguri, West Bengal\nğŸ“Š **Current AQI:** 340 (Very Poor)\nğŸ”´ **PM2.5:** 171 Î¼g/mÂ³\nğŸ™ï¸ **City Type:** City\nğŸ“Œ **Coordinates:** 26.52Â°N, 88.73Â°E\n\n**About Jalpaiguri:**\nImportant city in West Bengal with city characteristics.\n\nâš ï¸ **Health Advisory:** Stay indoors. Keep windows closed. Use air purifiers. Seek medical attention if breathing issues occur.\n------------------------------------------------------------\nQ: Latest news about air quality\nA: **Delhi, Delhi - Current Air Quality**\n\nğŸ“Š **AQI:** 252 (Poor)\nğŸ”´ **PM2.5:** 105.9 Î¼g/mÂ³\nğŸŸ  **PM10:** 237.7 Î¼g/mÂ³\n\nğŸŒ¡ï¸ **Weather:**\n- Temperature: 12.1Â°C\n- Humidity: 82%\n- Wind: 0.0 m/s\n\nâš ï¸ **Health Impact:** Breathing discomfort to most people on prolonged exposure.\n\nğŸ’¡ **Advisory:** Avoid outdoor activities. Use N95 masks if going outside. Run air purifiers indoors.\n\nï¿½\n------------------------------------------------------------\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# === INTERACTIVE RAG CHAT ===\nprint('\\n' + '='*60)\nprint('ğŸŒ Environmental RAG Chat')\nprint('Features: Live AQI | Live Weather | Internet Search')\nprint('Commands: \"search: <query>\" for web search')\nprint('Type \"quit\" to exit')\nprint('='*60 + '\\n')\n\nwhile True:\n    q = input('You: ').strip()\n    if q.lower() in ['quit','exit','q']: \n        print('Goodbye! ğŸ‘‹')\n        break\n    if not q: continue\n    \n    # Direct web search\n    if q.lower().startswith('search:'):\n        query = q[7:].strip()\n        print(f'\\nğŸ” Searching: {query}')\n        results = search_internet(query)\n        if results:\n            for i, r in enumerate(results, 1):\n                print(f'{i}. {r[\"title\"]}')\n                print(f'   {r[\"snippet\"][:200]}...')\n        else:\n            print('No results found.')\n        print()\n        continue\n    \n    # RAG-enhanced response\n    response = rag_generate(q)\n    \n    # Add live data\n    for city in CITIES:\n        if city in q.lower():\n            aqi = get_live_aqi(city)\n            weather = get_live_weather(city)\n            if aqi:\n                response += f'\\n\\nğŸ“Š LIVE ({city.title()}): AQI={aqi[\"aqi\"]} ({aqi[\"category\"]}), PM2.5={aqi[\"pm25\"]:.1f}'\n            if weather:\n                response += f'\\nğŸŒ¡ï¸ Weather: {weather[\"temp\"]}Â°C, {weather[\"humidity\"]}% humidity'\n            break\n    \n    print(f'\\nğŸ¤– Bot: {response}\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T04:30:39.138264Z","iopub.execute_input":"2025-12-12T04:30:39.138582Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸŒ Environmental RAG Chat\nFeatures: Live AQI | Live Weather | Internet Search\nCommands: \"search: <query>\" for web search\nType \"quit\" to exit\n============================================================\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  <WHAT IS THE FUTURE FORECAST OF KOLKATA>\n"},{"name":"stdout","text":"\nğŸ¤– Bot: **Kolkata, West Bengal - Current Air Quality**\n\nğŸ“Š **AQI:** 424 (Severe)\nğŸ”´ **PM2.5:** 317.7 Î¼g/mÂ³\nğŸŸ  **PM10:** 343.2 Î¼g/mÂ³\n\nğŸŒ¡ï¸ **Weather:**\n- Temperature: 15.01Â°C\n- Humidity: 63%\n- Wind: 1.01 m/s\n\nâš ï¸ **Health Impact:** Serious health effects. Avoid outdoor activities.\n\nğŸ’¡ **Advisory:** Stay indoors. Keep windows closed. Use air purifiers. Seek medical attention if breathing issues occur.\n\nğŸ“Š LIVE (Kolkata): AQI=424 (Severe), PM2.5=309.9\nğŸŒ¡ï¸ Weather: 19.95Â°C, 73% humidity\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  <Forecast of Kolkata temperature>\n"},{"name":"stdout","text":"\nğŸ¤– Bot: **Kolkata, West Bengal - 5-Day Forecast**\n\n**Day 1 (Fri 12 Dec):**\n- ğŸŒ¡ï¸ Temp: 17Â°C | ğŸ’§ Humidity: 78%\n- â˜ï¸ Condition: Clear Sky\n- ğŸ”´ AQI: 426 (Severe)\n\n**Day 2 (Fri 12 Dec):**\n- ğŸŒ¡ï¸ Temp: 22Â°C | ğŸ’§ Humidity: 52%\n- â˜ï¸ Condition: Clear Sky\n- ğŸ”´ AQI: 426 (Severe)\n\n**Day 3 (Fri 12 Dec):**\n- ğŸŒ¡ï¸ Temp: 27Â°C | ğŸ’§ Humidity: 24\n\nğŸ“Š LIVE (Kolkata): AQI=424 (Severe), PM2.5=309.9\nğŸŒ¡ï¸ Weather: 19.95Â°C, 73% humidity\n\n","output_type":"stream"}],"execution_count":null}]}